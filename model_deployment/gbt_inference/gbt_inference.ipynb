{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Gradient-Boosted-Tree-Inferencing\" data-toc-modified-id=\"Gradient-Boosted-Tree-Inferencing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Gradient Boosted Tree Inferencing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preparation\" data-toc-modified-id=\"Preparation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Regression\" data-toc-modified-id=\"Regression-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Regression</a></span></li><li><span><a href=\"#Binary-Classification\" data-toc-modified-id=\"Binary-Classification-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Binary Classification</a></span></li><li><span><a href=\"#Multiclass-Classification\" data-toc-modified-id=\"Multiclass-Classification-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Multiclass Classification</a></span></li></ul></li><li><span><a href=\"#C++-Implementation\" data-toc-modified-id=\"C++-Implementation-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>C++ Implementation</a></span></li></ul></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.260822Z",
     "start_time": "2021-02-07T18:25:13.175096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2021-02-07 10:25:19 \n",
      "\n",
      "CPython 3.6.4\n",
      "IPython 7.15.0\n",
      "\n",
      "numpy 1.18.5\n",
      "pandas 1.0.5\n",
      "sklearn 0.23.1\n",
      "m2cgen 0.9.0\n",
      "xgboost 1.2.1\n"
     ]
    }
   ],
   "source": [
    "# 1. magic to print version\n",
    "# 2. magic so that the notebook will reload external python modules\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import m2cgen as m2c\n",
    "import sklearn.datasets as datasets\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# prevent scientific notations\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,sklearn,m2cgen,xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very common in industry setting to prototype a machine learning model in Python and translate it into other languages such as C++, Java, etc, when it comes to deploying. This usually happens where the core application is written in other languages such as C++, Java, etc. and it is an extremely time sensitive application where we can't afford the cost of calling an external API to fetch the model prediction.\n",
    "\n",
    "In this article, we'll be looking at how we can achieve this with Gradient Boosted Trees, specifically XGBoost. Different library might have different ways to doing this, but the concept should be similar.\n",
    "\n",
    "**Tree Structure**\n",
    "\n",
    "A typical model dump from XGBoost looks like the following:\n",
    "\n",
    "```\n",
    "booster[0]:\n",
    "0:[bmi<0.00942232087] yes=1,no=2,missing=1\n",
    "\t1:[bmi<-0.0218342301] yes=3,no=4,missing=3\n",
    "\t\t3:[bmi<-0.0584798381] yes=7,no=8,missing=7\n",
    "\t\t\t7:leaf=25.84091\n",
    "\t\t\t8:leaf=33.0292702\n",
    "\t\t4:[bp<0.0270366594] yes=9,no=10,missing=9\n",
    "\t\t\t9:leaf=38.7487526\n",
    "\t\t\t10:leaf=51.0882378\n",
    "\t2:[bp<0.0235937908] yes=5,no=6,missing=5\n",
    "\t\t5:leaf=53.0696678\n",
    "\t\t6:leaf=69.4000015\n",
    "booster[1]:\n",
    "0:[bmi<0.00511107268] yes=1,no=2,missing=1\n",
    "\t1:[bp<0.0390867069] yes=3,no=4,missing=3\n",
    "\t\t3:[bmi<-0.0207564179] yes=7,no=8,missing=7\n",
    "\t\t\t7:leaf=21.0474758\n",
    "\t\t\t8:leaf=27.7326946\n",
    "\t\t4:[bmi<0.000799824367] yes=9,no=10,missing=9\n",
    "\t\t\t9:leaf=36.1850548\n",
    "\t\t\t10:leaf=14.9188232\n",
    "\t2:[bmi<0.0730132312] yes=5,no=6,missing=5\n",
    "\t\t5:[bp<6.75072661e-05] yes=11,no=12,missing=11\n",
    "\t\t\t11:leaf=31.3889732\n",
    "\t\t\t12:leaf=43.4056664\n",
    "\t\t6:[bp<-0.0498541184] yes=13,no=14,missing=13\n",
    "\t\t\t13:leaf=13.0395498\n",
    "\t\t\t14:leaf=59.377037\n",
    "```\n",
    "\n",
    "There are 3 distinct information:\n",
    "\n",
    "- `booster` Gradient Boosting Tree is an ensemble tree method, each new booster indicates the start of a new tree. The number of trees we have will be equivalent to the number of trees we specified for the model (e.g. for the sklearn XGBoost API, `n_estimators` controls this) multiplied by the number of distinct classes. For regression model or binary classification model, the number of booster in the model dump will be exactly equal to the number of trees we've specified. Whereas for multi class classification, say we have 3 classes, then tree 0 will contribute to the raw prediction of class 0, tree 1 to class 1, tree 2 to class 2, tree 3 to class 0 and so on.\n",
    "- `node` Following the booster is each tree's if-else structure. e.g. for node 0, if the feature `bmi` is less than a threshold, then it will branch to node 1 else it will branch to node 2.\n",
    "- `leaf` Once we reach the leaf, we can accumulate the response prediction. e.g. node 7 is a leaf, and the prediction for this node is 25.84091.\n",
    "\n",
    "\n",
    "**Raw Prediction**\n",
    "\n",
    "We mentioned that to get the prediction for a given input, we sum up the response prediction associated from each tree's leaf node. The holds true for regression models, but for other models, we will need to perform a transformation on top the raw prediction to get to the probabilities. e.g. for when building a binary classification, a logistic transformation will be needed on top of the raw prediction, whereas for the multi-class classification, a softmax transformation is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the examples below, be it regression, binary classification or multi class classification all follow the same structure.\n",
    "\n",
    "- We load some pre-processed data.\n",
    "- Train a quick XGBoost model.\n",
    "- Dump the raw model to disk.\n",
    "- Generate a sample prediction so we can later verify whether the prediction matches with the model converted to cpp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.369007Z",
     "start_time": "2021-02-07T18:25:19.263740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age    sex    bmi     bp\n",
       "0  0.038  0.051  0.062  0.022\n",
       "1 -0.002 -0.045 -0.051 -0.026\n",
       "2  0.085  0.051  0.044 -0.006\n",
       "3 -0.089 -0.045 -0.012 -0.037\n",
       "4  0.005 -0.045 -0.036  0.022"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "X = X[[\"age\", \"sex\", \"bmi\", \"bp\"]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.421190Z",
     "start_time": "2021-02-07T18:25:19.371371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.0, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=2, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model_params = {\n",
    "    'n_estimators': 2,\n",
    "    'max_depth': 3,\n",
    "    'base_score': 0.0\n",
    "}\n",
    "regression_model = XGBRegressor(**regression_model_params).fit(X, y)\n",
    "regression_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.479705Z",
     "start_time": "2021-02-07T18:25:19.423567Z"
    }
   },
   "outputs": [],
   "source": [
    "regression_model.get_booster().dump_model(\"regression.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.521771Z",
     "start_time": "2021-02-07T18:25:19.484379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([96.475334], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.predict(X.iloc[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.573940Z",
     "start_time": "2021-02-07T18:25:19.532177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.24456934, -1.36232827,  1.55433334, -2.0869092 , -1.27760482],\n",
       "       [-0.46503462, -0.57657929, -0.2033143 ,  0.43042571,  1.98019634],\n",
       "       [ 1.0967453 ,  1.31568265,  0.40073014, -0.88575625,  0.72711376],\n",
       "       ...,\n",
       "       [-3.17646599, -2.97878542,  0.32401442,  0.12710402, -0.63318634],\n",
       "       [-0.41224819,  0.17380558,  1.04229889, -1.62625451, -1.24718999],\n",
       "       [-1.02487223, -0.70828082,  0.55578021, -0.70007904, -0.43269446]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = datasets.make_classification(n_samples=10000, n_features=5, random_state=42, n_classes=2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.637949Z",
     "start_time": "2021-02-07T18:25:19.577514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              grow_policy='lossguide', importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=3, n_jobs=0,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method='hist',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model_params = {\n",
    "    'n_estimators': 3,\n",
    "    'max_depth': 3,\n",
    "    'tree_method': 'hist',\n",
    "    'grow_policy': 'lossguide'\n",
    "}\n",
    "binary_model = XGBClassifier(**binary_model_params).fit(X, y)\n",
    "binary_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.675808Z",
     "start_time": "2021-02-07T18:25:19.640919Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_model.get_booster().dump_model(\"binary_class.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.729845Z",
     "start_time": "2021-02-07T18:25:19.688789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2894203, 0.7105797]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array([[0.0, 0.2, 0.4, 0.6, 0.8]])\n",
    "binary_model.predict_proba(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.778573Z",
     "start_time": "2021-02-07T18:25:19.732064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.100</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.900</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.700</td>\n",
       "      <td>3.200</td>\n",
       "      <td>1.300</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.600</td>\n",
       "      <td>3.100</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000</td>\n",
       "      <td>3.600</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0              5.100             3.500              1.400             0.200\n",
       "1              4.900             3.000              1.400             0.200\n",
       "2              4.700             3.200              1.300             0.200\n",
       "3              4.600             3.100              1.500             0.200\n",
       "4              5.000             3.600              1.400             0.200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True, as_frame=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.825299Z",
     "start_time": "2021-02-07T18:25:19.782537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=2, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_class_model_params = {\n",
    "    'n_estimators': 2,\n",
    "    'max_depth': 3\n",
    "}\n",
    "multi_class_model = XGBClassifier(**multi_class_model_params).fit(X, y)\n",
    "multi_class_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.867799Z",
     "start_time": "2021-02-07T18:25:19.829309Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_class_model.get_booster().dump_model(\"multi_class.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.906184Z",
     "start_time": "2021-02-07T18:25:19.870241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6092037 , 0.19627656, 0.19451974]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
    "multi_class_model.predict_proba(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C++ Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the content is about implementing the boosted tree inferencing logic in C++, all the code resides in the [`gbt_inference`](https://github.com/ethen8181/machine-learning/tree/master/model_deployment/gbt_inference/gbt_inference) folder for those interested. In practice, we don't always have to rely on naive code that we've implemented to solidify our understanding. e.g. the [m2cgen (Model 2 Code Generator)](https://github.com/BayesWitnesses/m2cgen) project is one of the many projects out there that focuses on converting a trained model into native code. If we export our regression model, we can see that the inferencing logic is indeed a bunch of if else statements followed by a summation at the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.949779Z",
     "start_time": "2021-02-07T18:25:19.908688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double score(double * input) {\n",
      "    double var0;\n",
      "    if ((input[2]) >= (0.009422321)) {\n",
      "        if ((input[3]) >= (0.02359379)) {\n",
      "            var0 = 69.4;\n",
      "        } else {\n",
      "            var0 = 53.069668;\n",
      "        }\n",
      "    } else {\n",
      "        if ((input[2]) >= (-0.02183423)) {\n",
      "            if ((input[3]) >= (0.02703666)) {\n",
      "                var0 = 51.088238;\n",
      "            } else {\n",
      "                var0 = 38.748753;\n",
      "            }\n",
      "        } else {\n",
      "            if ((input[2]) >= (-0.058479838)) {\n",
      "                var0 = 33.02927;\n",
      "            } else {\n",
      "                var0 = 25.84091;\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "    double var1;\n",
      "    if ((input[2]) >= (0.0051110727)) {\n",
      "        if ((input[2]) >= (0.07301323)) {\n",
      "            if ((input[3]) >= (-0.04985412)) {\n",
      "                var1 = 59.377037;\n",
      "            } else {\n",
      "                var1 = 13.03955;\n",
      "            }\n",
      "        } else {\n",
      "            if ((input[3]) >= (0.000067507266)) {\n",
      "                var1 = 43.405666;\n",
      "            } else {\n",
      "                var1 = 31.388973;\n",
      "            }\n",
      "        }\n",
      "    } else {\n",
      "        if ((input[3]) >= (0.039086707)) {\n",
      "            if ((input[2]) >= (0.00079982437)) {\n",
      "                var1 = 14.918823;\n",
      "            } else {\n",
      "                var1 = 36.185055;\n",
      "            }\n",
      "        } else {\n",
      "            if ((input[2]) >= (-0.020756418)) {\n",
      "                var1 = 27.732695;\n",
      "            } else {\n",
      "                var1 = 21.047476;\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "    return (var0) + (var1);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code = m2c.export_to_c(regression_model)\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Blog: Roll your own XGBoost model](https://medium.com/swlh/roll-your-own-xgboost-model-7490106b9523)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
