{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18415461",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Response-Knowledge-Distillation\" data-toc-modified-id=\"Response-Knowledge-Distillation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Response Knowledge Distillation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Data Preprocessing</a></span></li><li><span><a href=\"#Teacher-Model\" data-toc-modified-id=\"Teacher-Model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Teacher Model</a></span></li><li><span><a href=\"#Student-Model\" data-toc-modified-id=\"Student-Model-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Student Model</a></span></li><li><span><a href=\"#Benchmark\" data-toc-modified-id=\"Benchmark-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Benchmark</a></span></li></ul></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07383deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    html {\n",
       "        font-size: 18px !important;\n",
       "    }\n",
       "\n",
       "    body {\n",
       "        background-color: #FFF !important;\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    body .notebook-app {\n",
       "        background-color: #FFF !important;\n",
       "    }\n",
       "\n",
       "    #header {\n",
       "        box-shadow: none !important;\n",
       "    }\n",
       "\n",
       "    #notebook {\n",
       "        padding-top: 0px;\n",
       "    }\n",
       "\n",
       "    #notebook-container {\n",
       "        box-shadow: none;\n",
       "        -webkit-box-shadow: none;\n",
       "        padding: 10px;\n",
       "    }\n",
       "\n",
       "    div.cell {\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border: 1px dashed #CCCCCC;\n",
       "    }\n",
       "\n",
       "    .edit_mode div.cell.selected {\n",
       "        border: 1px dashed #828282;\n",
       "    }\n",
       "\n",
       "    div.output_wrapper {\n",
       "        margin-top: 8px;\n",
       "    }\n",
       "\n",
       "    a {\n",
       "        color: #383838;\n",
       "    }\n",
       "\n",
       "    code,\n",
       "    kbd,\n",
       "    pre,\n",
       "    samp {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem !important;\n",
       "    }\n",
       "\n",
       "    h1 {\n",
       "        font-size: 2rem !important;\n",
       "        font-weight: 500 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: uppercase !important;\n",
       "    }\n",
       "\n",
       "    h2 {\n",
       "        font-size: 1.8rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: none !important;\n",
       "    }\n",
       "\n",
       "    h3 {\n",
       "        font-size: 1.5rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        font-style: italic !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    h4,\n",
       "    h5,\n",
       "    h6 {\n",
       "        font-size: 1rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    .prompt {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem;\n",
       "        text-align: right;\n",
       "        line-height: 1.21429rem;\n",
       "    }\n",
       "\n",
       "    /* INTRO PAGE */\n",
       "\n",
       "    .toolbar_info,\n",
       "    .list-container {\n",
       "        ;\n",
       "    }\n",
       "    /* NOTEBOOK */\n",
       "\n",
       "    div#header-container {\n",
       "        display: none !important;\n",
       "    }\n",
       "\n",
       "    div#notebook {\n",
       "        border-top: none;\n",
       "        font-size: 1rem;\n",
       "    }\n",
       "\n",
       "    div.input_prompt {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .code_cell div.input_prompt:after,\n",
       "    div.output_prompt:after {\n",
       "        content: '\\25b6';\n",
       "    }\n",
       "\n",
       "    div.output_prompt {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    div.input_area {\n",
       "        border-radius: 0px;\n",
       "        border: 1px solid #d8d8d8;\n",
       "    }\n",
       "\n",
       "    div.output_area pre {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    div.output_subarea {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .rendered_html pre,\n",
       "    .rendered_html table,\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        border: 1px #828282 solid;\n",
       "        font-size: 0.75rem;\n",
       "        font-family: 'Menlo', monospace;\n",
       "    }\n",
       "\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        padding: 5px 10px;\n",
       "    }\n",
       "\n",
       "    .rendered_html th {\n",
       "        font-weight: normal;\n",
       "        background: #f8f8f8;\n",
       "    }\n",
       "\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "\n",
       "    div.output_html {\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    table.dataframe tr {\n",
       "        border: 1px #CCCCCC;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border-radius: 0px;\n",
       "    }\n",
       "\n",
       "    div.cell.edit_mode {\n",
       "        border-radius: 0px;\n",
       "        border: thin solid #CF5804;\n",
       "    }\n",
       "\n",
       "    span.ansiblue {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    span.ansigray {\n",
       "        color: #d8d8d8;\n",
       "    }\n",
       "\n",
       "    span.ansigreen {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    span.ansipurple {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    span.ansired {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    span.ansiyellow {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    div.output_stderr {\n",
       "        background-color: #D43132;\n",
       "    }\n",
       "\n",
       "    div.output_stderr pre {\n",
       "        color: #e8e8e8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython.CodeMirror {\n",
       "        background: #F8F8F8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython div.CodeMirror-selected {\n",
       "        background: #e8e8e8 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-gutters {\n",
       "        background: #F8F8F8;\n",
       "        border-right: 0px;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-linenumber {\n",
       "        color: #b8b8b8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-cursor {\n",
       "        border-left: 1px solid #585858 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-atom {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-number {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-property,\n",
       "    .cm-s-ipython span.cm-attribute {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-keyword {\n",
       "        font-weight: normal;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-string {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-operator {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-builtin {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable-2 {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-def {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-error {\n",
       "        background: #FFBDBD;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-tag {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-link {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-matchingbracket {\n",
       "        text-decoration: underline;\n",
       "         !important;\n",
       "    }\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading the format for the notebook\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "os.chdir(os.path.join('..', '..', 'notebook_format'))\n",
    "\n",
    "from formats import load_style\n",
    "load_style(css_style='custom2.css', plot_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17fa0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Ethen\n",
      "\n",
      "Last updated: 2022-08-26\n",
      "\n",
      "torch       : 1.12.1\n",
      "datasets    : 2.3.2\n",
      "transformers: 4.20.1\n",
      "evaluate    : 0.2.2\n",
      "numpy       : 1.21.6\n",
      "pandas      : 1.2.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "\n",
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from time import perf_counter\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "%watermark -a 'Ethen' -d -u -p torch,datasets,transformers,evaluate,numpy,pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0268da0e",
   "metadata": {},
   "source": [
    "# Response Knowledge Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf9884",
   "metadata": {},
   "source": [
    "In this documentation, we'll deep dive into a technique called knowledge distillation that's commonly used to compress large model, a.k.a. teacher model, into a smaller model, a.k.a student model. The hope is that these student models, which typically have fewer layers or/and fewer neurons per layer will be capable of reproducing the behavior of teacher models while being more light weight. In other words, making the model more cost efficient when it comes to serving in production setting without lossing too much performance. And just to clarify, as knowledge distillation is a broad topic, there are two primary types of knowledge distillation, task-specific knowledge distillation (left) and task-agnostic knowledge distillation (right). Here, our primary focus will be the former.\n",
    "\n",
    "<img src=\"img/distillation_task.png\" width=\"70%\" height=\"70%\">\n",
    "\n",
    "Task specific response knowledge distillation involves optimizing a weighted combination of two objective functions\n",
    "\n",
    "\\begin{align}\n",
    "L = \\alpha L_{CE} + (1 - \\alpha) L_{KD} \\text{, where } \\alpha \\in [0, 1]\n",
    "\\end{align}\n",
    "\n",
    "$L_{CE}$ is the cross entropy loss between the student logit $z_s$ and our one hot encoded ground truth labels $y$:\n",
    "\n",
    "\\begin{align}\n",
    "L_{CE} = - \\sum^c_{j=1}y_j \\text{log} \\sigma_j(z_s, 1)\n",
    "\\end{align}\n",
    "\n",
    "Where $\\sigma_i$ is our softmax output that takes the model's logit, $z$ ($z_t$ stands for teacher model's logit, whereas $z_s$ stands for student model's logit), as well as a temperature scaling parameter, $T$, as its inputs. $\\sigma_i = \\frac{exp\\left(z_i / T \\right)}{\\sum_{j} \\exp\\left(z_j / T \\right)}$. Here, the temperature parameter for softmax function is 1, which makes this the standard loss function that we generally optimize towards in supervised classification settings. \n",
    "\n",
    "$L_{KD}$ For knowledge distillation loss part, we are essentially add a KL-divergence loss between teacher model's response with student model's response. By adding this loss function, we are training our student model so it will become better at mimicking similar predictions as the teacher.\n",
    "\n",
    "\\begin{align}\n",
    "L_{KD} = - T^2 \\sum^c_{j=1}\\sigma_j(z_t, T) \\text{log} \\frac{\\sigma_j(z_t, T)}{\\sigma_j(z_s, T)}\n",
    "\\end{align}\n",
    "\n",
    "The idea behind temperature scaling is that teacher model tend to assign extremely high predicted scores to the true class, as such it doesn't provide too much additional information beyond what dataset's ground truth label was already provided. To tackle this issue, temperature scaling acts as a scaling parameter to \"soften\" our predictions. The intuition behind this it allows us to learn \"ish\" concepts in our data, e.g. we have a 1-ish 7 (a 7 that looks like a 1, or more formally, although our model predicted 7 with the highest score, it still assign some amount of score to 1). Note:\n",
    "\n",
    "- When a student model is a lot smaller than a teacher model, we tend to keep a smaller temperature. Because as we raise the temperature parameter, the resulting predicted distribution may start to contain too much \"knowledge\" for the student to capture effectively.\n",
    "- Once our student model has been trained, the temperature parameter $T$, is set back to 1 during inferencing stage.\n",
    "- There's a multiplication term $T^2$, in our knowledge distillation loss Since the magnitudes of the gradients produced by the soft targets scale as $1/T^2$. It is important to add a multiplication term back to ensure contribution from the ground truth hard target and the teacher's predicted soft target remains roughly equal.\n",
    "\n",
    "As we can see, the main idea behind response knowledge distillation is that while training our student model, instead of solely optimizing for our task's original loss function using our dataset's ground truth label (e.g. in classification task this may be cross entropy loss), we will augment it with the teacher model's predicted output probability. In our loss function we will have a parameter $\\alpha$ that controls weighting between the two loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c925d2",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d576158",
   "metadata": {},
   "source": [
    "For this example, we will be using qqp (Quora Question Pairs2) [text classification task]((https://huggingface.co/tasks/text-classification)) from the [glue benchmark](https://huggingface.co/datasets/glue). These are collection of question pairs from the community question-answering website Quora. Our task is to determine whether a pair of questions are semantically equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbbabb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0ebd93f798495bbc2eaf31b124b3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question1', 'question2', 'label', 'idx'],\n",
       "        num_rows: 363846\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question1', 'question2', 'label', 'idx'],\n",
       "        num_rows: 40430\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question1', 'question2', 'label', 'idx'],\n",
       "        num_rows: 390965\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = load_dataset('glue', 'qqp')\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92e63f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question1': 'What can one do after MBBS?',\n",
       " 'question2': 'What do i do after my MBBS ?',\n",
       " 'label': 1,\n",
       " 'idx': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset_dict['train'][3]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f80c1da",
   "metadata": {},
   "source": [
    "## Teacher Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b38af2",
   "metadata": {},
   "source": [
    "To establish our baseline, we'll piggyback on one of the pretrained models available from huggingface hub. In this case, we'll pick a teacher model that is already trained on our targeted dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba918b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters:  109483778\n"
     ]
    }
   ],
   "source": [
    "teacher_checkpoint = 'textattack/bert-base-uncased-QQP'\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_checkpoint)\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(teacher_checkpoint).to(device)\n",
    "print('# of parameters: ', teacher_model.num_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed7ba0",
   "metadata": {},
   "source": [
    "We generate a sample prediction using our tokenizer and model. Double confirming our result matches with the [pipeline wrapper class](https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/pipelines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8369a332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2054,  2064,  2028,  2079,  2044, 16914,  5910,  1029,   102,\n",
       "          2054,  2079,  1045,  2079,  2044,  2026, 16914,  5910,  1029,   102]],\n",
       "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='cuda:0')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = teacher_tokenizer(\n",
    "    example['question1'],\n",
    "    example['question2'],\n",
    "    return_tensors='pt'\n",
    ").to(teacher_model.device)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb1591a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0223, 0.9777]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model.eval()\n",
    "with torch.no_grad():\n",
    "    output = teacher_model(**tokenized)\n",
    "    batch_scores = F.softmax(output.logits, dim=-1)\n",
    "\n",
    "batch_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "597fafa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'LABEL_1', 'score': 0.9777140021324158}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model=teacher_checkpoint, device=teacher_model.device)\n",
    "output = classifier({\"text\": example['question1'], \"text_pair\": example['question2']})\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a562bf7a",
   "metadata": {},
   "source": [
    "## Student Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abafbb5",
   "metadata": {},
   "source": [
    "As always, we are free to choose different student models and compare results, though as a general principle, we typically avoid distilling different model family against each other, as different inputs/tokens will result in different embeddings, and knowledge transfering different spaces tend to not work well.\n",
    "\n",
    "In the next code chunk, apart from the typically step of initiating our student model using `.from_pretrained` method, we also copy some additional config such as number of labels as well as label id to label name mapping from the teacher model's config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15d87d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_checkpoint = 'distilbert-base-uncased'\n",
    "\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_checkpoint)\n",
    "\n",
    "student_config = AutoConfig.from_pretrained(\n",
    "    student_checkpoint,\n",
    "    num_labels=teacher_model.config.num_labels,\n",
    "    id2label=teacher_model.config.id2label,\n",
    "    label2id=teacher_model.config.label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae893d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters:  66955010\n"
     ]
    }
   ],
   "source": [
    "def student_model_init():\n",
    "    student_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        student_checkpoint,\n",
    "        config=student_config\n",
    "    ).to(device)\n",
    "    return student_model\n",
    "\n",
    "\n",
    "student_model = student_model_init()\n",
    "print('# of parameters: ', student_model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e502b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset, tokenizer):\n",
    "    def tokenize_fn(batch):\n",
    "        return tokenizer(batch[\"question1\"], batch[\"question2\"], truncation=True)\n",
    "\n",
    "    return dataset.map(\n",
    "        tokenize_fn,\n",
    "        batched=True,\n",
    "        num_proc=8,\n",
    "        remove_columns=[\"question1\", \"question2\", \"idx\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80ed9740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a8f61aaa83ba2ee2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-daebdc7105b1e8f7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-20d395268d52b4e3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8bc658db78dde795.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f0374f1cbc06fa12.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-2e9088b1dbb8434c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-7bbccc3a4229a83e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-4c824600f621243f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-51ae49f9d8a95037.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-591dc6edfbe0d7c2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-302a4412aa27fb83.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-39d35fb67c02d467.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-458b6d6a7aa7b7f8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-cc09642df872468a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-452ef0103d9c6221.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-377807dbd74b5216.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-c7bdc7a185c7f2c8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-c6fe5844c32761d8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f16094dbb6270595.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-074946734d50b003.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-93678765a8db8d07.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-2dc173cc4049ad28.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-480e4d963d7d4495.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-2b01915a997e8ff1.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset_dict_student_tokenized = tokenize_dataset(dataset_dict, student_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e43079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'input_ids': [101,\n",
       "  2129,\n",
       "  2003,\n",
       "  1996,\n",
       "  2166,\n",
       "  1997,\n",
       "  1037,\n",
       "  8785,\n",
       "  3076,\n",
       "  1029,\n",
       "  2071,\n",
       "  2017,\n",
       "  6235,\n",
       "  2115,\n",
       "  2219,\n",
       "  6322,\n",
       "  1029,\n",
       "  102,\n",
       "  2029,\n",
       "  2504,\n",
       "  1997,\n",
       "  17463,\n",
       "  8156,\n",
       "  2003,\n",
       "  2438,\n",
       "  2005,\n",
       "  1996,\n",
       "  11360,\n",
       "  1046,\n",
       "  14277,\n",
       "  2102,\n",
       "  2629,\n",
       "  1029,\n",
       "  102],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict_student_tokenized['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c92452",
   "metadata": {},
   "source": [
    "For model performance, we'll compute some of the standard text classification metrics, Huggingface evaluate allows us to combine multiple metric's calculation in one go using the `.combine` method. As `roc_auc` expects a different input (it requires the predicted score instead of predicted labels) compared to `f1`, `precision`, `recall`, we load it separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf7c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 1.0, 'precision': 1.0, 'recall': 1.0}\n"
     ]
    }
   ],
   "source": [
    "clf_metrics = evaluate.combine([\"f1\", \"precision\", \"recall\"])\n",
    "roc_auc_metric = evaluate.load(\"roc_auc\")\n",
    "\n",
    "results = clf_metrics.compute(predictions=[0, 1], references=[0, 1])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4d5aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    scores, labels = pred\n",
    "    predictions = np.argmax(scores, axis=1)\n",
    "    metrics = clf_metrics.compute(predictions=predictions, references=labels)\n",
    "    metrics['roc_auc'] = roc_auc_metric.compute(prediction_scores=scores[:, 1], references=labels)['roc_auc']\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f79457c",
   "metadata": {},
   "source": [
    "In the next few code chunk, we'll first train a student model with and without knowledge distillation for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17d04c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/mingyuliu/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/mingyuliu/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/mingyuliu/.local/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 363846\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17058\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17058' max='17058' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17058/17058 40:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.285100</td>\n",
       "      <td>0.270191</td>\n",
       "      <td>0.843404</td>\n",
       "      <td>0.816137</td>\n",
       "      <td>0.872556</td>\n",
       "      <td>0.951686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.219800</td>\n",
       "      <td>0.254518</td>\n",
       "      <td>0.861569</td>\n",
       "      <td>0.830724</td>\n",
       "      <td>0.894793</td>\n",
       "      <td>0.959855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.257736</td>\n",
       "      <td>0.863629</td>\n",
       "      <td>0.846228</td>\n",
       "      <td>0.881760</td>\n",
       "      <td>0.961481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 40430\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-qqp/checkpoint-5686\n",
      "Configuration saved in distilbert-base-uncased-finetuned-qqp/checkpoint-5686/config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-qqp/checkpoint-5686/pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-qqp/checkpoint-5686/tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-qqp/checkpoint-5686/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 40430\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-qqp/checkpoint-11372\n",
      "Configuration saved in distilbert-base-uncased-finetuned-qqp/checkpoint-11372/config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-qqp/checkpoint-11372/pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-qqp/checkpoint-11372/tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-qqp/checkpoint-11372/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 40430\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-qqp/checkpoint-17058\n",
      "Configuration saved in distilbert-base-uncased-finetuned-qqp/checkpoint-17058/config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-qqp/checkpoint-17058/pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-qqp/checkpoint-17058/tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-qqp/checkpoint-17058/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from distilbert-base-uncased-finetuned-qqp/checkpoint-11372 (score: 0.25451797246932983).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17058, training_loss=0.24440976354326394, metrics={'train_runtime': 2436.7937, 'train_samples_per_second': 447.94, 'train_steps_per_second': 7.0, 'total_flos': 2.2013605137213264e+16, 'train_loss': 0.24440976354326394, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_train_epochs = 3\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "\n",
    "student_finetuned_checkpoint = \"distilbert-base-uncased-finetuned-qqp\"\n",
    "student_training_args = TrainingArguments(\n",
    "    output_dir=student_finetuned_checkpoint,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=weight_decay,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "student_trainer = Trainer(\n",
    "    model_init=student_model_init,\n",
    "    args=student_training_args,\n",
    "    tokenizer=student_tokenizer, \n",
    "    train_dataset=dataset_dict_student_tokenized['train'],\n",
    "    eval_dataset=dataset_dict_student_tokenized['validation'],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "student_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094be856",
   "metadata": {},
   "source": [
    "In order for us to finetune for model using knowledge distillation, we will subclass the `TrainingArguments` to include our two hyperparameters, $\\alpha$ and $T$, as well as `Trainer` to mainly overwrite its `compute_loss` method so we can add our knowledge distillation loss term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e6da70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainingArguments(TrainingArguments):\n",
    "    def __init__(self, *args, alpha=0.5, temperature=1.5, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "\n",
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, *args, teacher_model=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher = teacher_model\n",
    "        # place teacher on same device as student\n",
    "        self._move_model_to_device(self.teacher,self.model.device)\n",
    "        self.teacher.eval()\n",
    "\n",
    "        self.kl_div_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # compute student and teacher output\n",
    "        outputs_student = model(**inputs)\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = self.teacher(**inputs)\n",
    "\n",
    "        # Soften probabilities and compute distillation loss\n",
    "        # note, the kl divergence loss expects the input to be in log-space\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html\n",
    "        distillation_loss = self.kl_div_loss(\n",
    "            F.log_softmax(outputs_student.logits / self.args.temperature, dim=-1),\n",
    "            F.softmax(outputs_teacher.logits / self.args.temperature, dim=-1)\n",
    "        ) * (self.args.temperature ** 2)\n",
    "        # Return weighted student loss\n",
    "        loss = self.args.alpha * outputs_student.loss + (1. - self.args.alpha) * distillation_loss\n",
    "        return (loss, outputs_student) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3813c8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/mingyuliu/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/mingyuliu/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/mingyuliu/.local/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 363846\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17058\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17058' max='17058' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17058/17058 1:05:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>0.408516</td>\n",
       "      <td>0.831750</td>\n",
       "      <td>0.852827</td>\n",
       "      <td>0.811690</td>\n",
       "      <td>0.951295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.376300</td>\n",
       "      <td>0.396593</td>\n",
       "      <td>0.850368</td>\n",
       "      <td>0.867762</td>\n",
       "      <td>0.833658</td>\n",
       "      <td>0.958391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>0.400977</td>\n",
       "      <td>0.856636</td>\n",
       "      <td>0.870724</td>\n",
       "      <td>0.842996</td>\n",
       "      <td>0.960325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 40430\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-5686\n",
      "Configuration saved in distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-5686/config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-5686/pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-5686/tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-5686/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 40430\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-11372\n",
      "Configuration saved in distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-11372/config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-11372/pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-11372/tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-11372/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 40430\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-17058\n",
      "Configuration saved in distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-17058/config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-17058/pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-17058/tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-17058/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from distilbert-base-uncased-finetuned-distillation-qqp/checkpoint-11372 (score: 0.3965926468372345).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17058, training_loss=0.3921033198647013, metrics={'train_runtime': 3955.2862, 'train_samples_per_second': 275.969, 'train_steps_per_second': 4.313, 'total_flos': 2.2013605137213264e+16, 'train_loss': 0.3921033198647013, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_distillation_checkpoint = \"distilbert-base-uncased-finetuned-distillation-qqp\"\n",
    "student_distillation_training_args = DistillationTrainingArguments(\n",
    "    output_dir=student_distillation_checkpoint,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=weight_decay,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "student_distillation_trainer = DistillationTrainer(\n",
    "    model_init=student_model_init,\n",
    "    args=student_distillation_training_args,\n",
    "    tokenizer=student_tokenizer,\n",
    "    teacher_model=teacher_model, \n",
    "    train_dataset=dataset_dict_student_tokenized['train'],\n",
    "    eval_dataset=dataset_dict_student_tokenized['validation'],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "student_distillation_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b32405",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e127b4ba",
   "metadata": {},
   "source": [
    "When determining which model to move forward with production, we usually look at model performance, latency, as well as memory (a.k.a model size). We'll create a helper class for measuring these key aspects, run our models through it for a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0540811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Benchmark:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        latency_warmup: int = 10,\n",
    "        latency_rounds: int = 100,\n",
    "        perf_batch_size: int = 128,\n",
    "        perf_round_digits: int = 3\n",
    "    ):\n",
    "        self.dataset = dataset\n",
    "        self.latency_warmup = latency_warmup\n",
    "        self.latency_rounds = latency_rounds\n",
    "        self.perf_batch_size = perf_batch_size\n",
    "        self.perf_round_digits = perf_round_digits\n",
    "\n",
    "        self.temp_model_path = 'model.pt'\n",
    "\n",
    "    def run(self, tokenizer, model, run_name):\n",
    "        \"\"\"run benchmark for a given tokenizer and model\n",
    "        we can provide a run_name to differentiate the results\n",
    "        from different runs in the final dictionary.\n",
    "        \n",
    "        e.g.\n",
    "        {\n",
    "            \"run_name\": {\n",
    "                'size_mb': 417.73,\n",
    "                'num_parameters': 109483778,\n",
    "                'latency_avg_ms': 8.33,\n",
    "                'latency_std_ms': 1.16,\n",
    "                'f1': 0.878,\n",
    "                'precision': 0.867,\n",
    "                'recall': 0.89,\n",
    "                'roc_auc': 0.968\n",
    "            }\n",
    "        }\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        size = self.compute_size(model)\n",
    "        latency = self.compute_latency(tokenizer, model)\n",
    "        performance = self.compute_performance(tokenizer, model)\n",
    "\n",
    "        # merge various metrics into one single dictionary\n",
    "        metrics = {**size, **latency, **performance}\n",
    "        return {run_name: metrics}\n",
    "    \n",
    "    def predict(self, example, tokenizer, model):\n",
    "        inputs = tokenizer(\n",
    "            example['question1'],\n",
    "            example['question2'],\n",
    "            return_tensors='pt'\n",
    "        ).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            output = model(**inputs.to(model.device))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_size(self, model):\n",
    "        \"\"\"save the model's parameter temporarily to local path for calculating model size.\n",
    "        Once calculation is done, purge the checkpoint.\n",
    "        Size is reported in megabtyes.\n",
    "\n",
    "        https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "        \"\"\"\n",
    "        torch.save(model.state_dict(), self.temp_model_path)\n",
    "        size_mb = os.path.getsize(self.temp_model_path) / (1024 * 1024)\n",
    "        size_mb = round(size_mb, 2)\n",
    "        os.remove(self.temp_model_path)\n",
    "        print(f\"Model size (MB): {size_mb}\")\n",
    "        print(f\"# of parameters: {model.num_parameters()}\")\n",
    "        return {\"size_mb\": size_mb, \"num_parameters\": model.num_parameters()}\n",
    "    \n",
    "    def compute_latency(self, tokenizer, model):\n",
    "        \"\"\"\n",
    "        Pick the first example of the input dataset, compute the average latency as well as\n",
    "        standard deviation over a configurable number of runs.\n",
    "        Latency is reported in milliseconds.\n",
    "        \"\"\"\n",
    "        example = self.dataset[0]\n",
    "        latencies = []\n",
    "\n",
    "        for _ in range(self.latency_warmup):\n",
    "            _ = self.predict(example, tokenizer, model)\n",
    "\n",
    "        for _ in range(self.latency_rounds):\n",
    "            start_time = perf_counter()\n",
    "            _ = self.predict(example, tokenizer, model)\n",
    "            latency = perf_counter() - start_time\n",
    "            latencies.append(latency)\n",
    "\n",
    "        # Compute run statistics\n",
    "        latency_avg_ms = round(1000 * np.mean(latencies), 2)\n",
    "        latency_std_ms = round(1000 * np.std(latencies), 2)\n",
    "        print(f\"Average latency (ms): {latency_avg_ms} +\\- {latency_std_ms}\")\n",
    "        return {\"latency_avg_ms\": latency_avg_ms, \"latency_std_ms\": latency_std_ms}\n",
    "        \n",
    "    def compute_performance(self, tokenizer, model):\n",
    "        \"\"\"compute f1/precision/recall/roc_auc metrics around sequence classification.\"\"\"\n",
    "        clf_metrics = evaluate.combine([\"f1\", \"precision\", \"recall\"])\n",
    "        roc_auc_metric = evaluate.load(\"roc_auc\")\n",
    "\n",
    "        scores = []\n",
    "        predictions = []\n",
    "        references = []\n",
    "        \n",
    "        dataset_tokenized = tokenize_dataset(self.dataset, tokenizer)\n",
    "        \n",
    "        data_collator = DataCollatorWithPadding(tokenizer)\n",
    "        data_loader = DataLoader(dataset_tokenized, batch_size=self.perf_batch_size, collate_fn=data_collator)\n",
    "        for example in data_loader:\n",
    "            labels = example.pop('labels')\n",
    "            with torch.no_grad():\n",
    "                output = model(**example.to(model.device))\n",
    "                score = F.softmax(output.logits, dim=-1)\n",
    "                prediction = score.argmax(dim=-1)\n",
    "\n",
    "            scores += tensor_to_list(score[:, 1])\n",
    "            predictions += tensor_to_list(prediction)\n",
    "            references += tensor_to_list(labels)\n",
    "\n",
    "        metrics = clf_metrics.compute(predictions=predictions, references=references)\n",
    "        metrics['roc_auc'] = roc_auc_metric.compute(prediction_scores=scores, references=references)['roc_auc']\n",
    "        for metric, value in metrics.items():\n",
    "            metrics[metric] = round(value, self.perf_round_digits)\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    \n",
    "def tensor_to_list(tensor):\n",
    "    return tensor.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c1b7b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB): 417.73\n",
      "# of parameters: 109483778\n",
      "Average latency (ms): 7.01 +\\- 0.63\n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-0c6ac1d39dfd9e94.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-7aa70ce020a63c9d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-58720fa6daa16de3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-554217326819c7b0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-eda7739157194c24.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d08f8b13da74e2bf.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-675828f6d2b994cd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f92fb802867c268e.arrow\n"
     ]
    }
   ],
   "source": [
    "benchmark_metrics_dict = {}\n",
    "benchmark = Benchmark(dataset_dict['validation'])\n",
    "benchmark_metrics = benchmark.run(teacher_tokenizer, teacher_model, 'bert_uncased_teacher')\n",
    "benchmark_metrics_dict.update(benchmark_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a793671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB): 255.45\n",
      "# of parameters: 66955010\n",
      "Average latency (ms): 4.24 +\\- 0.62\n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-51ae49f9d8a95037.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-591dc6edfbe0d7c2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-302a4412aa27fb83.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-39d35fb67c02d467.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-458b6d6a7aa7b7f8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-cc09642df872468a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-452ef0103d9c6221.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-377807dbd74b5216.arrow\n"
     ]
    }
   ],
   "source": [
    "benchmark_metrics = benchmark.run(\n",
    "    student_tokenizer,\n",
    "    student_trainer.model,\n",
    "    'distilbert_student'\n",
    ")\n",
    "benchmark_metrics_dict.update(benchmark_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "301a2880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB): 255.45\n",
      "# of parameters: 66955010\n",
      "Average latency (ms): 4.02 +\\- 0.34\n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-51ae49f9d8a95037.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-591dc6edfbe0d7c2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-302a4412aa27fb83.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-39d35fb67c02d467.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-458b6d6a7aa7b7f8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-cc09642df872468a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-452ef0103d9c6221.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mingyuliu/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-377807dbd74b5216.arrow\n"
     ]
    }
   ],
   "source": [
    "benchmark_metrics = benchmark.run(\n",
    "    student_tokenizer,\n",
    "    student_distillation_trainer.model,\n",
    "    'distilbert_distillation_student'\n",
    ")\n",
    "benchmark_metrics_dict.update(benchmark_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6f53b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_mb</th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>latency_avg_ms</th>\n",
       "      <th>latency_std_ms</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert_uncased_teacher</th>\n",
       "      <td>417.73</td>\n",
       "      <td>109483778</td>\n",
       "      <td>7.01</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_student</th>\n",
       "      <td>255.45</td>\n",
       "      <td>66955010</td>\n",
       "      <td>4.24</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_distillation_student</th>\n",
       "      <td>255.45</td>\n",
       "      <td>66955010</td>\n",
       "      <td>4.02</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 size_mb  num_parameters  latency_avg_ms  \\\n",
       "bert_uncased_teacher              417.73       109483778            7.01   \n",
       "distilbert_student                255.45        66955010            4.24   \n",
       "distilbert_distillation_student   255.45        66955010            4.02   \n",
       "\n",
       "                                 latency_std_ms     f1  precision  recall  \\\n",
       "bert_uncased_teacher                       0.63  0.878      0.867   0.890   \n",
       "distilbert_student                         0.62  0.862      0.831   0.895   \n",
       "distilbert_distillation_student            0.34  0.850      0.868   0.834   \n",
       "\n",
       "                                 roc_auc  \n",
       "bert_uncased_teacher               0.968  \n",
       "distilbert_student                 0.960  \n",
       "distilbert_distillation_student    0.959  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(benchmark_metrics_dict, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd3efa",
   "metadata": {},
   "source": [
    "The final table is a comparison on our teacher model (bert), and two student model (distilbert), where one of the students was trained with knowledge distilation loss, and the other wasn't. Quick observations are: we can definitely shrink our model size and improve latency by using a student model without much loss in terms of model performance. Note, we also didn't spend too much time tuning additional loss weighting, $\\alpha$, and temperature scaling, $T$ hyperparameters that comes with knowledge distillation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6befdd48",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681c7e41",
   "metadata": {},
   "source": [
    "- [Blog: Task-specific knowledge distillation for BERT using Transformers & Amazon SageMaker](https://www.philschmid.de/knowledge-distillation-bert-transformers)\n",
    "- [Blog: Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT](https://medium.com/huggingface/distilbert-8cf3380435b5)\n",
    "- [Blog: Knowledge Distillation: Principles, Algorithms, Applications](https://neptune.ai/blog/knowledge-distillation)\n",
    "- [Blog: Weeknotes: Distilling distilled transformers](https://lewtun.github.io/blog/weeknotes/nlp/huggingface/transformers/2021/01/17/wknotes-distillation-and-generation.html)\n",
    "- [Doc: Neural Network Distiller - Knowledge Distillation](https://intellabs.github.io/distiller/knowledge_distillation.html)\n",
    "- [Paper: V. Sanh, L. Debut, J. Chaumond, T. Wolf - DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter - 2019](https://arxiv.org/abs/1910.01108)\n",
    "- [Paper: G. Hinton, O. Vinyals, J. Dean - Distilling the Knowledge in a Neural Network - 2015](https://arxiv.org/abs/1910.01108)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "233.719px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
